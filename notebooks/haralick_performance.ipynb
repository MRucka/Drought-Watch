{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qou1wPW8Rfts"
   },
   "source": [
    "This notebook contains prealpha Haralick features calculation code along with time tests. <br>\n",
    "**TODO: vectorization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28Oe8qUoumrF"
   },
   "source": [
    "### Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RHOWHCNZ3iAp"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import skimage.transform\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "\n",
    "# time measuring \n",
    "import time\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGqvUU_EzF0O"
   },
   "outputs": [],
   "source": [
    "LOAD_PATH = '../examples/multispec_img.npy'\n",
    "NUM_REP = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LcLoYJFMVxw"
   },
   "source": [
    "### Sample image loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 567,
     "status": "ok",
     "timestamp": 1616412261288,
     "user": {
      "displayName": "Drought Watch",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7qRb4hR3gYNg3v1yqsO-vaTNmHHZbVNiVC5gU=s64",
      "userId": "12686926332801949832"
     },
     "user_tz": -60
    },
    "id": "If2qu71cMaf_",
    "outputId": "d2c3d5f1-64af-44d9-b130-b8b219bd0ea1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "picture shape = (65, 65, 8)\n"
     ]
    }
   ],
   "source": [
    "img = np.load(LOAD_PATH)\n",
    "print(f'img shape = {img.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dm6UNgCFeEdN"
   },
   "source": [
    "### Handcrafted features calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8jXUpvjq1Br"
   },
   "source": [
    "Features should be normalized therefore corresponding minima and maxima were precalculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qp8ZIQmmnKD6"
   },
   "outputs": [],
   "source": [
    "min_max_dict = {\n",
    "  'min': {\n",
    "    'arvi': -0.11833266519719478,\n",
    "    'evi': -0.022776836311584298,\n",
    "    'h_glcm_hom': 0.08442477027905304,\n",
    "    'h_glcm_mean': 253.47205872093022,\n",
    "    'h_glcm_sosv': 56737.77884884521,\n",
    "    'h_mean': 19.422487037859074,\n",
    "    'h_std': 1.4369563844979523,\n",
    "    'i_glcm_mean': 83.60073284883721,\n",
    "    'i_glcm_sosv': 14235.545471465104,\n",
    "    'i_mean': 0.030918037472179714,\n",
    "    'ndvi': -0.07979946801639441,\n",
    "    'ndwi': -0.25679003333176903,\n",
    "    's_glcm_correlation': 0.07081265512018585,\n",
    "    's_glcm_mean': 7.709087693798451,\n",
    "    's_glcm_sosv': 350.9815934669858,\n",
    "    's_mean': 0.030918037472179714,\n",
    "    'swir1_mean': 0.000253393665158371,\n",
    "    'swir2_mean': 0.00021719457013574662,\n",
    "    'tir1_mean': 0.0004084000464090962,\n",
    "    'tir2_mean': 0.0004158255017983525},\n",
    " 'max': {\n",
    "    'arvi': 0.5567921249833387,\n",
    "    'evi': 0.7661288947704729,\n",
    "    'h_glcm_hom': 0.9988599263466074,\n",
    "    'h_glcm_mean': 524.0095466085272,\n",
    "    'h_glcm_sosv': 142741.5464050787,\n",
    "    'h_mean': 289.8848410461291,\n",
    "    'h_std': 139.78125522930878,\n",
    "    'i_glcm_mean': 133.80282829457366,\n",
    "    'i_glcm_sosv': 17622.45531356966,\n",
    "    'i_mean': 0.9989349490751622,\n",
    "    'ndvi': 0.6946931383411229,\n",
    "    'ndwi': 0.4088313329186157,\n",
    "    's_glcm_correlation': 0.9709833637974503,\n",
    "    's_glcm_mean': 105.0412703488372,\n",
    "    's_glcm_sosv': 10330.89298209496,\n",
    "    's_mean': 0.9989349490751622,\n",
    "    'swir1_mean': 0.45185752407471874,\n",
    "    'swir2_mean': 0.3782851838960436,\n",
    "    'tir1_mean': 0.8493412228796844,\n",
    "    'tir2_mean': 0.8320232045480914}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rTAlE3yhMD46"
   },
   "outputs": [],
   "source": [
    "def rgb2hsi(red, green, blue): # input: normalized RGB\n",
    "  # output:\n",
    "  # H - Hue [0, 360]\n",
    "  # S - Saturation [0, 1]\n",
    "  # I - Intensity [0, 255]\n",
    "  \n",
    "  temp = 0.5 * (red - green + red - blue) / (np.sqrt((red - green) * (red - green) + (red - blue) * (green - blue) + 0.001))\n",
    "  temp = np.arccos(temp)\n",
    "  temp2 = green >= blue\n",
    "  temp2 = np.multiply(temp, temp2)\n",
    "  temp3 = green < blue\n",
    "  temp4 = 2 * np.pi - temp\n",
    "  temp4 = np.multiply(temp3, temp4)\n",
    "\n",
    "  H = (temp2 + temp4) * 180 / np.pi\n",
    "  S = (1 - 3 * (np.minimum(np.minimum(red, green), blue))/(red+ g reen + blue + 0.001))\n",
    "  I = ((red + green + blue) / 3) * 255\n",
    "  \n",
    "  return H,S,I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0c2LKO8MGRY"
   },
   "outputs": [],
   "source": [
    "def create_glcm(H, S, I): # input: HSI\n",
    "  # output: GLCM matrices\n",
    "\n",
    "  H_GLCM = greycomatrix(image = H.astype(int), distances = [1], \n",
    "                        angles = [0, np.pi / 4, np.pi / 2, 3 * np.pi / 4], levels = 361)\n",
    "  S_GLCM = greycomatrix(image = (S * 100).astype(int), distances = [1], \n",
    "                        angles = [0, np.pi / 4, np.pi / 2, 3 * np.pi / 4], levels = 101)\n",
    "  I_GLCM = greycomatrix(image = (np.round_(I)).astype(int), distances = [1], \n",
    "                        angles=[0, np.pi / 4, np.pi / 2, 3 * np.pi / 4], levels = 256)\n",
    "\n",
    "  return H_GLCM, S_GLCM, I_GLCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "beHLLBDXnV9i"
   },
   "outputs": [],
   "source": [
    "def mean_GLCM(H_GLCM, S_GLCM, I_GLCM): # input: GLCM matrices\n",
    "  # output: GLCM means\n",
    "\n",
    "  H_GLCM = np.squeeze(H_GLCM)\n",
    "  H_GLCM = np.mean(H_GLCM, axis  =2)\n",
    "\n",
    "  S_GLCM = np.squeeze(S_GLCM)\n",
    "  S_GLCM = np.mean(S_GLCM, axis = 2)\n",
    "\n",
    "  I_GLCM = np.squeeze(I_GLCM)\n",
    "  I_GLCM = np.mean(I_GLCM, axis = 2)\n",
    "\n",
    "  return H_GLCM, S_GLCM, I_GLCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2106,
     "status": "ok",
     "timestamp": 1616412267855,
     "user": {
      "displayName": "Drought Watch",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7qRb4hR3gYNg3v1yqsO-vaTNmHHZbVNiVC5gU=s64",
      "userId": "12686926332801949832"
     },
     "user_tz": -60
    },
    "id": "Cn2PqsjHL7Ca",
    "outputId": "a53508f9-1ca2-4051-c959-b435b9fcfba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean elapsed times (seconds):\n",
      "{'ARVI/EVI/NDVI/NDWI': 0.00019965693354606628,\n",
      " 'GLCM': 0.006812989711761475,\n",
      " 'HSI': 0.00019410252571105957,\n",
      " 'H_GLCM': 0.005897361785173416,\n",
      " 'I_GLCM': 0.0007641203701496124,\n",
      " 'S_GLCM': 0.0013883747160434723,\n",
      " 'assign': 1.6842037439346313e-05,\n",
      " 'channels slicing': 4.649162292480469e-06,\n",
      " 'norm': 0.00013906508684158325}\n",
      "\n",
      "Total time for 64 iterations: 0.9866983890533447s\n",
      "\n",
      "Calculated features:\n",
      "[0.583294407539082,\n",
      " 0.4205302594307736,\n",
      " 0.6268935771851192,\n",
      " 0.530733633409135,\n",
      " 0.7037631531148164,\n",
      " 0.5673630504946428,\n",
      " 0.09887176630078556,\n",
      " 0.09887176630078556,\n",
      " 0.9261081124994331,\n",
      " 0.9295599175018712,\n",
      " 0.47112820685939716,\n",
      " 0.37422085828175966,\n",
      " 0.5644887136328478,\n",
      " 0.4509478981206715,\n",
      " 0.12314932605348573,\n",
      " 0.09872824486093075,\n",
      " 0.024813594090530272,\n",
      " 0.898877097358546,\n",
      " 0.5086731561023332,\n",
      " 0.2263605138691972]\n"
     ]
    }
   ],
   "source": [
    "elapsed_times = {} # elapsed time will be measured and averaged for each section denoted by a proper comment\n",
    "\n",
    "for _ in range(NUM_REP):\n",
    "  \n",
    "  # channels slicing\n",
    "  start = time.time()\n",
    "\n",
    "  R = img[:, :, 0]\n",
    "  G = img[:, :, 1]\n",
    "  B = img[:, :, 2] \n",
    "  NIR = img[:, :, 3]\n",
    "  SWIR1 = img[:, :, 4]\n",
    "  SWIR2 = img[:, :, 5] \n",
    "  TIR1 = img[:, :, 6]\n",
    "  TIR2 = img[:, :, 7]\n",
    "\n",
    "  end = time.time() - start\n",
    "  elapsed_times.setdefault('channels slicing', 0)\n",
    "  elapsed_times['channels slicing'] += end\n",
    "\n",
    "  # HSI \n",
    "  start = time.time()\n",
    "\n",
    "  H, S, I = rgb2hsi(R, G, B) \n",
    "\n",
    "  end = time.time() - start\n",
    "  elapsed_times.setdefault('HSI', 0)\n",
    "  elapsed_times['HSI'] += end\n",
    "\n",
    "  # GLCM\n",
    "  start = time.time()\n",
    "\n",
    "  H_GLCM_Org, S_GLCM_Org, I_GLCM_Org = create_glcm(H, S, I) # 4 matrices for each band (one per direction)\n",
    "  H_GLCM, S_GLCM, I_GLCM = mean_GLCM(H_GLCM_Org, S_GLCM_Org, I_GLCM_Org) \n",
    "  H_GLCM_prob = (H_GLCM / np.sum(H_GLCM)) + 0.00001 # for numeric stability\n",
    "  S_GLCM_prob = (S_GLCM / np.sum(S_GLCM)) + 0.00001\n",
    "  I_GLCM_prob = (I_GLCM / np.sum(I_GLCM)) + 0.00001\n",
    "\n",
    "  end = time.time() - start\n",
    "  elapsed_times.setdefault('GLCM', 0)\n",
    "  elapsed_times['GLCM'] += end\n",
    "\n",
    "  # *VI\n",
    "  start = time.time()\n",
    "\n",
    "  arvi = ((NIR - (2 * R - B)) / (NIR + (2 * R + B) + 0.0001)).mean() \n",
    "  arvi = (arvi - min_max_dict['min']['arvi']) / (min_max_dict['max']['arvi'] - min_max_dict['min']['arvi'])\n",
    "  evi = (2.5 * ((NIR - R) / (NIR + (R) * 6 - (B) * 7.5 + 1 + 0.0001))).mean()\n",
    "  evi = (evi - min_max_dict['min']['evi']) / (min_max_dict['max']['evi'] - min_max_dict['min']['evi'])\n",
    "  ndvi = ((NIR - R)/((NIR + R) + 0.0001)).mean()\n",
    "  ndvi = (ndvi - min_max_dict['min']['ndvi']) / (min_max_dict['max']['ndvi'] - min_max_dict['min']['ndvi'])\n",
    "  ndwi = ((NIR - SWIR1)/(NIR + SWIR1 + 0.0001)).mean()\n",
    "  ndwi = (ndwi - min_max_dict['min']['ndwi']) / (min_max_dict['max']['ndwi'] - min_max_dict['min']['ndwi'])\n",
    "\n",
    "  end = time.time() - start\n",
    "  elapsed_times.setdefault('ARVI/EVI/NDVI/NDWI', 0)\n",
    "  elapsed_times['ARVI/EVI/NDVI/NDWI'] += end\n",
    "\n",
    "  # bands normalization\n",
    "  start = time.time()\n",
    "\n",
    "  H_std = H.std()\n",
    "  H_std = (H_std - min_max_dict['min']['h_std']) / (min_max_dict['max']['h_std'] - min_max_dict['min']['h_std'])\n",
    "  H_mean = H.mean()\n",
    "  H_mean = (H_mean - min_max_dict['min']['h_mean']) / (min_max_dict['max']['h_mean'] - min_max_dict['min']['h_mean'])\n",
    "  S_mean = S.mean()\n",
    "  S_mean = (S_mean - min_max_dict['min']['s_mean']) / (min_max_dict['max']['s_mean'] - min_max_dict['min']['s_mean'])\n",
    "  I_mean = S.mean()\n",
    "  I_mean = (I_mean - min_max_dict['min']['i_mean']) / (min_max_dict['max']['i_mean'] - min_max_dict['min']['i_mean'])\n",
    "  TIR1_mean = TIR1.mean()\n",
    "  TIR1_mean = (TIR1_mean - min_max_dict['min']['tir1_mean']) / (min_max_dict['max']['tir1_mean'] - min_max_dict['min']['tir1_mean'])\n",
    "  TIR2_mean = TIR2.mean()\n",
    "  TIR2_mean = (TIR2_mean - min_max_dict['min']['tir2_mean']) / (min_max_dict['max']['tir2_mean'] - min_max_dict['min']['tir2_mean'])\n",
    "  SWIR1_mean = SWIR1.mean()\n",
    "  SWIR1_mean = (SWIR1_mean - min_max_dict['min']['swir1_mean']) / (min_max_dict['max']['swir1_mean'] - min_max_dict['min']['swir1_mean'])\n",
    "  SWIR2_mean = SWIR2.mean()\n",
    "  SWIR2_mean = (SWIR2_mean - min_max_dict['min']['swir2_mean']) / (min_max_dict['max']['swir2_mean'] - min_max_dict['min']['swir2_mean'])\n",
    "\n",
    "  end = time.time() - start\n",
    "  elapsed_times.setdefault('norm', 0)\n",
    "  elapsed_times['norm'] += end\n",
    "\n",
    "  # H_GLCM\n",
    "  start = time.time()\n",
    "\n",
    "  H_GLCM_mean = np.array(H_GLCM_prob * np.array(range(H_GLCM_prob.shape[1]))).sum()\n",
    "  H_GLCM_mean = (H_GLCM_mean - min_max_dict['min']['h_glcm_mean']) / (min_max_dict['max']['h_glcm_mean'] - min_max_dict['min']['h_glcm_mean'])\n",
    "  raw = np.empty_like(H_GLCM_prob)\n",
    "  raw[...] = np.arange(H_GLCM_prob.shape[0])\n",
    "  raw = np.transpose(raw)\n",
    "  minus_mean = (raw - H_GLCM_prob.mean()) ** 2\n",
    "  H_GLCM_sosv = np.apply_over_axes(np.sum, minus_mean * H_GLCM_prob, axes = (0, 1))[0][0]\n",
    "  H_GLCM_sosv = (H_GLCM_sosv - min_max_dict['min']['h_glcm_sosv']) / (min_max_dict['max']['h_glcm_sosv'] - min_max_dict['min']['h_glcm_sosv']) \n",
    "  H_GLCM_Homogeneity = (greycoprops(P = H_GLCM_Org, prop = 'homogeneity')).mean()\n",
    "  H_GLCM_Homogeneity = (H_GLCM_Homogeneity - min_max_dict['min']['h_glcm_hom']) / (min_max_dict['max']['h_glcm_hom'] - min_max_dict['min']['h_glcm_hom']) \n",
    "\n",
    "  end = time.time() - start\n",
    "  elapsed_times.setdefault('H_GLCM', 0)\n",
    "  elapsed_times['H_GLCM'] += end\n",
    "\n",
    "  # S_GLCM\n",
    "  start = time.time()\n",
    "\n",
    "  S_GLCM_mean = np.array(S_GLCM_prob * np.array(range(S_GLCM_prob.shape[1]))).sum()\n",
    "  S_GLCM_mean = (S_GLCM_mean - min_max_dict['min']['s_glcm_mean']) / (min_max_dict['max']['s_glcm_mean'] - min_max_dict['min']['s_glcm_mean'])\n",
    "  raw = np.empty_like(S_GLCM_prob)\n",
    "  raw[...] = np.arange(S_GLCM_prob.shape[0])\n",
    "  raw = np.transpose(raw)\n",
    "  minus_mean = (raw - S_GLCM_prob.mean()) ** 2\n",
    "  S_GLCM_sosv = np.apply_over_axes(np.sum, minus_mean * S_GLCM_prob, axes = (0, 1))[0][0] \n",
    "  S_GLCM_sosv = (S_GLCM_sosv - min_max_dict['min']['s_glcm_sosv']) / (min_max_dict['max']['s_glcm_sosv'] - min_max_dict['min']['s_glcm_sosv'])\n",
    "  S_GLCM_Correlation = (greycoprops(P = S_GLCM_Org, prop = 'correlation')).mean()\n",
    "  S_GLCM_Correlation = (S_GLCM_Correlation - min_max_dict['min']['s_glcm_correlation']) / (min_max_dict['max']['s_glcm_correlation'] - min_max_dict['min']['s_glcm_correlation'])\n",
    "\n",
    "  end = time.time() - start\n",
    "  elapsed_times.setdefault('S_GLCM', 0)\n",
    "  elapsed_times['S_GLCM'] += end\n",
    "\n",
    "  # I_GLCM\n",
    "  start = time.time()\n",
    "\n",
    "  I_GLCM_mean = np.array(I_GLCM_prob * np.array(range(I_GLCM_prob.shape[1]))).sum()\n",
    "  I_GLCM_mean = (I_GLCM_mean - min_max_dict['min']['i_glcm_mean']) / (min_max_dict['max']['i_glcm_mean'] - min_max_dict['min']['i_glcm_mean'])\n",
    "  raw = np.empty_like(I_GLCM_prob)\n",
    "  raw[...] = np.arange(I_GLCM_prob.shape[0])\n",
    "  raw = np.transpose(raw)\n",
    "  minus_mean = (raw - I_GLCM_prob.mean()) ** 2\n",
    "  I_GLCM_sosv = np.apply_over_axes(np.sum, minus_mean * I_GLCM_prob, axes=(0, 1))[0][0] \n",
    "  I_GLCM_sosv = (I_GLCM_sosv - min_max_dict['min']['i_glcm_sosv']) / (min_max_dict['max']['i_glcm_sosv'] - min_max_dict['min']['i_glcm_sosv'])\n",
    "\n",
    "  end = time.time() - start\n",
    "  elapsed_times.setdefault('I_GLCM', 0)\n",
    "  elapsed_times['I_GLCM'] += end\n",
    "\n",
    "  features = [arvi, evi, ndvi, ndwi, H_std, H_mean, S_mean, I_mean, TIR1_mean, TIR2_mean, SWIR1_mean, SWIR2_mean, H_GLCM_mean, \n",
    "              H_GLCM_sosv, H_GLCM_Homogeneity, S_GLCM_mean, S_GLCM_sosv, S_GLCM_Correlation, I_GLCM_mean, I_GLCM_sosv]\n",
    "\n",
    "  # assigning\n",
    "  start = time.time()\n",
    "\n",
    "  arr = np.array(features, dtype = np.float32)\n",
    "  ret_arr = np.zeros((65, 65, 1), dtype = np.float32)\n",
    "  ret_arr[0, 0 : 20, 0] = arr\n",
    "\n",
    "  end = time.time() - start\n",
    "  elapsed_times.setdefault('assign', 0)\n",
    "  elapsed_times['assign'] += end\n",
    "\n",
    "# means and total time calculation\n",
    "elapsed_means = {}\n",
    "total_time = 0\n",
    "\n",
    "for key, value in elapsed_times.items():\n",
    "  elapsed_means[key] = value / float(NUM_REP)\n",
    "  total_time += value\n",
    "\n",
    "print('Mean elapsed times (seconds):')\n",
    "pprint.pprint(elapsed_means)\n",
    "\n",
    "print(f'\\nTotal time for {NUM_REP} iterations: {total_time}s')\n",
    "\n",
    "print('\\nCalculated features:')\n",
    "pprint.pprint(features)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PerformanceTests.ipynb",
   "provenance": [
    {
     "file_id": "1IIStCd7HO3q_bABrDLSbDXCfnbvLfieW",
     "timestamp": 1610626842223
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
